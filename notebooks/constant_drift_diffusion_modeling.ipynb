{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('../src')))\n",
    "from constant_drift_diffusion import *\n",
    "from accumulators import *\n",
    "\n",
    "# bayesflow\n",
    "sys.path.append(os.path.abspath(os.path.join('../../BayesFlow')))\n",
    "from bayesflow.networks import InvariantNetwork, InvertibleNetwork\n",
    "from bayesflow.amortizers import SingleModelAmortizer\n",
    "from bayesflow.trainers import ParameterEstimationTrainer\n",
    "from bayesflow.diagnostics import *\n",
    "\n",
    "from tensorflow.keras.layers import Dense, GRU, LSTM, Conv1D, MultiHeadAttention, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for device in gpu_devices: tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation \n",
    "N_SIM = 500\n",
    "N_OBS = 100\n",
    "\n",
    "# bayesflow\n",
    "PARAM_NAMES = [\"a\", \"ndt\", \"bias\", \"kappa\"]\n",
    "N_PARAMS = len(PARAM_NAMES)\n",
    "N_EPOCHS = 50\n",
    "ITER_PER_EPOCH = 1000\n",
    "BATCH_SIZE = 32\n",
    "N_SAMPLES = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulator Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obs = 100\n",
    "a     = 3.0\n",
    "ndt   = 0.2\n",
    "bias  = 0.5\n",
    "kappa = 5\n",
    "theta = np.array([a, ndt, bias, kappa])\n",
    "\n",
    "unique_motions = np.array([-0.725, -0.675, -0.625, -0.575, -0.525, 0.525,  0.575,  0.625,  0.675,  0.725], dtype=np.float32)\n",
    "amplitude = np.repeat(unique_motions, 10)\n",
    "condition = to_categorical(pd.factorize(amplitude)[0])\n",
    "\n",
    "rt, resp = const_dm_simulator(theta, 1, amplitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 100, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_, x_ = const_dm_batch_simulator(32, 100)\n",
    "x_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 17:31:14.102872: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "sum_meta = {\n",
    "    'n_dense_s1': 2,\n",
    "    'n_dense_s2': 3,\n",
    "    'n_dense_s3': 2,\n",
    "    'n_equiv':    2,\n",
    "    'dense_s1_args': {'activation': 'relu', 'units': 32},\n",
    "    'dense_s2_args': {'activation': 'relu', 'units': 64},\n",
    "    'dense_s3_args': {'activation': 'relu', 'units': 32},\n",
    "}\n",
    "\n",
    "summary_net = InvariantNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invertable inference network\n",
    "meta_dict={\n",
    "    'n_coupling_layers': 5,\n",
    "    's_args': {\n",
    "        'units': [128, 128],\n",
    "        'activation': 'elu',\n",
    "        'initializer': 'glorot_uniform',\n",
    "    },\n",
    "    't_args': {\n",
    "        'units': [128, 128],\n",
    "        'activation': 'elu',\n",
    "        'initializer': 'glorot_uniform',\n",
    "    },\n",
    "    'alpha': 1.9,\n",
    "    'permute': True,\n",
    "    'use_act_norm': True,\n",
    "    'n_params': N_PARAMS\n",
    "}\n",
    "\n",
    "inference_net = InvertibleNetwork(meta_dict)\n",
    "\n",
    "# Connect summary and inference network\n",
    "amortizer = SingleModelAmortizer(inference_net, summary_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing networks from scratch.\n"
     ]
    }
   ],
   "source": [
    "# Learning-rate decay\n",
    "learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.0005, 1000, 0.99, staircase=True\n",
    ")\n",
    "\n",
    "trainer = ParameterEstimationTrainer(\n",
    "    network=amortizer, \n",
    "    generative_model=const_dm_batch_simulator,\n",
    "    learning_rate=learning_rate,\n",
    "    checkpoint_path='../src/selected_checkpoints/const_dm',\n",
    "    clip_value=3,\n",
    "    max_to_keep=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# online training\n",
    "losses = trainer.train_online(N_EPOCHS, ITER_PER_EPOCH, BATCH_SIZE, n_obs=N_OBS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paramter Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate and amortized inference\n",
    "p_, x_ = const_dm_batch_simulator(n_sim=N_SIM,n_obs=N_OBS)\n",
    "samples = amortizer.sample(x_, n_samples=N_SAMPLES)\n",
    "param_means = samples.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recovery plot\n",
    "true_vs_estimated(theta_true=p_, theta_est=param_means,\n",
    "                  param_names=PARAM_NAMES, dpi=300, figsize=(20,6),font_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(pd.DataFrame(samples[0], columns=PARAM_NAMES))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a30ec19090e2f2b1a106537d5c312817a43a20ac3d56ad8096fbad2e54ec1c01"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('cogModeling': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
