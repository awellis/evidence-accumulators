{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from numba import njit\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('../src')))\n",
    "from varying_drift_diffusion import *\n",
    "from motion_simulation import *\n",
    "from accumulators import *\n",
    "from threshold_dynamics import *\n",
    "\n",
    "# bayesflow\n",
    "sys.path.append(os.path.abspath(os.path.join('../../BayesFlow')))\n",
    "from bayesflow.networks import InvariantNetwork, InvertibleNetwork\n",
    "from bayesflow.amortizers import SingleModelAmortizer\n",
    "from bayesflow.trainers import ParameterEstimationTrainer\n",
    "from bayesflow.diagnostics import *\n",
    "\n",
    "from tensorflow.keras.layers import Dense, GRU, LSTM, Conv1D, MultiHeadAttention, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2\n",
    "c = 1\n",
    "\n",
    "a_lower, a_upper = linear_collapsing_bound(2, 1)\n",
    "plt.plot(np.arange(1e4), a_lower, label=\"lower\")\n",
    "plt.plot(np.arange(1e4), a_upper, label=\"upper\")\n",
    "plt.legend()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1.5\n",
    "c = 5\n",
    "max_iter = 1e4\n",
    "t = np.arange(max_iter) * 0.001\n",
    "a_lower = a*(t / (t + c))\n",
    "a_upper = a - a*(t / (t + c))\n",
    "\n",
    "plt.plot(np.arange(4000), a_upper[0:4000], label=\"upper\")\n",
    "plt.plot(np.arange(4000), a_lower[0:4000], label=\"lower\")\n",
    "plt.legend()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.5\n",
    "tau = 0.1\n",
    "max_iter = 1e4\n",
    "t = np.arange(max_iter) * 0.001\n",
    "a_upper = (a/2) * np.exp(-tau*t) + a/2\n",
    "a_lower = -(a/2) * np.exp(-tau*t) + a/2\n",
    "\n",
    "plt.plot(np.arange(1e4), a_upper, label=\"upper\")\n",
    "plt.plot(np.arange(1e4), a_lower, label=\"lower\")\n",
    "plt.legend()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2\n",
    "tau = 1\n",
    "a_lower, a_upper = exponential_collapsing_bound(a, tau)\n",
    "\n",
    "plt.plot(np.arange(1e4), a_upper, label=\"upper\")\n",
    "plt.plot(np.arange(1e4), a_lower, label=\"lower\")\n",
    "plt.legend()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "a_0 = 0.1\n",
    "\n",
    "lambd = 1\n",
    "k = 2\n",
    "\n",
    "max_iter = 1e4\n",
    "t = np.arange(max_iter) * 0.001\n",
    "\n",
    "a_upper = a - (1 - np.exp(-(t/lambd)**k)) * ((a/2) - a_0)\n",
    "a_lower = (1 - np.exp(-(t/lambd)**k)) * ((a/2) - a_0)\n",
    "\n",
    "\n",
    "plt.plot(np.arange(10000), a_upper[0:10000], label=\"upper\")\n",
    "plt.plot(np.arange(10000), a_lower[0:10000], label=\"lower\")\n",
    "plt.legend()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for device in gpu_devices: tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation \n",
    "N_SIM = 500\n",
    "N_OBS = 100\n",
    "\n",
    "# bayesflow\n",
    "PARAM_NAMES = [\"a\", \"ndt\", \"bias\", \"kappa\"]\n",
    "N_PARAMS = len(PARAM_NAMES)\n",
    "N_EPOCHS = 50\n",
    "ITER_PER_EPOCH = 1000\n",
    "BATCH_SIZE = 32\n",
    "N_SAMPLES = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulator Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obs = 100\n",
    "a     = 3.0\n",
    "ndt   = 0.2\n",
    "bias  = 0.5\n",
    "kappa = 5\n",
    "theta = np.array([a, ndt, bias, kappa])\n",
    "\n",
    "unique_motions = np.array([-0.725, -0.675, -0.625, -0.575, -0.525, 0.525,  0.575,  0.625,  0.675,  0.725], dtype=np.float32)\n",
    "amplitude = np.repeat(unique_motions, 10)\n",
    "motion_set, condition = motion_experiment_manual(1, amplitude, 1)\n",
    "\n",
    "rt, resp = var_dm_simulator(theta, 1, motion_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "p_, x_ = var_dm_batch_simulator(32, 100)\n",
    "x_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSummary(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, meta_inv, n_out=10):\n",
    "        super(CustomSummary, self).__init__()\n",
    "        self.inv = InvariantNetwork(meta_inv)\n",
    "        self.out = Dense(n_out)\n",
    "        \n",
    "    def call(self, x):\n",
    "        return self.out(self.inv(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_meta = {\n",
    "    'n_dense_s1': 2,\n",
    "    'n_dense_s2': 2,\n",
    "    'n_dense_s3': 2,\n",
    "    'n_equiv':    2,\n",
    "    'dense_s1_args': {'activation': 'relu', 'units': 32},\n",
    "    'dense_s2_args': {'activation': 'relu', 'units': 32},\n",
    "    'dense_s3_args': {'activation': 'relu', 'units': 32},\n",
    "}\n",
    "\n",
    "# invertable inference network\n",
    "inf_meta = {\n",
    "    'n_coupling_layers': 4,\n",
    "    's_args': {\n",
    "        'units': [128, 128],\n",
    "        'activation': 'elu',\n",
    "        'initializer': 'glorot_uniform',\n",
    "    },\n",
    "    't_args': {\n",
    "        'units': [128, 128],\n",
    "        'activation': 'elu',\n",
    "        'initializer': 'glorot_uniform',\n",
    "    },\n",
    "    'alpha': 1.9,\n",
    "    'permute': True,\n",
    "    'use_act_norm': True,\n",
    "    'n_params': N_PARAMS\n",
    "}\n",
    "\n",
    "inference_net = InvertibleNetwork(inf_meta)\n",
    "summary_net = CustomSummary(sum_meta)\n",
    "amortizer = SingleModelAmortizer(inference_net, summary_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning-rate decay\n",
    "learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.0005, 1000, 0.99, staircase=True\n",
    ")\n",
    "\n",
    "trainer = ParameterEstimationTrainer(\n",
    "    network=amortizer, \n",
    "    generative_model=var_dm_batch_simulator,\n",
    "    learning_rate=learning_rate,\n",
    "    checkpoint_path='../src/selected_checkpoints/time_var_dm2',\n",
    "    clip_value=3,\n",
    "    max_to_keep=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning-rate decay\n",
    "# trainer.optimizer = tf.keras.optimizers.Adam(0.00007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%time\n",
    "# # # online training\n",
    "# losses = trainer.train_online(5, ITER_PER_EPOCH, BATCH_SIZE, n_obs=N_OBS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate and amortized inference\n",
    "p_, x_ = var_dm_batch_simulator(n_sim=N_SIM,n_obs=N_OBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = amortizer.sample(x_, n_samples=N_SAMPLES)\n",
    "param_means = samples.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recovery plot\n",
    "f = true_vs_estimated(theta_true=p_, theta_est=param_means,\n",
    "                  param_names=PARAM_NAMES, dpi=300, figsize=(20,6),font_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Based Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate\n",
    "n_sbc = 5000\n",
    "n_post_samples_sbc = 250\n",
    "params, sim_data = var_dm_batch_simulator(n_sbc, N_OBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amortized inference\n",
    "param_samples = np.concatenate([amortizer.sample(x, n_post_samples_sbc)\n",
    "                                for x in tf.split(sim_data, 10, axis=0)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank-plot\n",
    "f = plot_sbc(param_samples, params, param_names=PARAM_NAMES, figsize=(24, 8), bins=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Eye Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation\n",
    "true_params, sim_data = var_dm_batch_simulator(N_SIM, N_OBS)\n",
    "\n",
    "# Amortized inference\n",
    "param_samples = np.concatenate([amortizer.sample(x, N_SAMPLES)\n",
    "                                for x in tf.split(sim_data, 10, axis=0)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Posterior z-score\n",
    "# Compute posterior means and stds\n",
    "post_means = param_samples.mean(1)\n",
    "post_stds = param_samples.std(1)\n",
    "post_vars = param_samples.var(1)\n",
    "\n",
    "# Compute posterior z score\n",
    "post_z_score = (post_means - true_params) / post_stds\n",
    "\n",
    "### Posterior contraction, i.e., 1 - post_var / prior_var\n",
    "prior_a = (0.5, 0.1, 0.2, 0.0) # lower bound of uniform prior\n",
    "prior_b = (3.0, 0.5, 0.8, 10.0) # upper bound of uniform prior\n",
    "\n",
    "# Compute prior vars analytically\n",
    "prior_vars = np.array([(b-a)**2/12 for a,b in zip(prior_a, prior_b)])\n",
    "# prior_vars = np.concatenate((prior_vars[0:2], np.array([0.0025]), prior_vars[2:]))\n",
    "post_cont = 1 - post_vars / prior_vars\n",
    "\n",
    "# Plotting time\n",
    "f, axarr = plt.subplots(1, 4, figsize=(16, 4))\n",
    "for i, (p, ax) in enumerate(zip(PARAM_NAMES, axarr.flat)):\n",
    "\n",
    "\n",
    "    ax.scatter(post_cont[:, i], post_z_score[:, i], color='#8f2727', alpha=0.7)\n",
    "    ax.set_title(p, fontsize=20)\n",
    "    sns.despine(ax=ax)\n",
    "    ax.set_xlim([-0.1, 1.05])\n",
    "    ax.set_ylim([-3.5, 3.5])\n",
    "    ax.grid(color='black', alpha=0.1)\n",
    "    ax.set_xlabel('Posterior contraction', fontsize=14)\n",
    "    if i == 0 or i == 3:\n",
    "        ax.set_ylabel('Posterior z-score', fontsize=14)\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Retrodictive Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empirical Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "directory = str(Path().absolute())\n",
    "path = str(Path(directory).parents[0]) + '/data/single_sub_data.csv'\n",
    "data = np.loadtxt(open(path, 'rb'), delimiter=\",\", skiprows=1)\n",
    "\n",
    "# subset data\n",
    "data_subset = data[(data[:, 1] == 1) & (data[:, 2] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get one hot encoded amplitude\n",
    "amplitude = data_subset[:, 4]\n",
    "condition = get_hot_encoded_amplitude(amplitude)\n",
    "\n",
    "# prepare data for amortized inference\n",
    "final_data = np.hstack((np.expand_dims(data_subset[:, 6], axis=1),\n",
    "                        np.expand_dims(data_subset[:, 5], axis=1), condition))\n",
    "\n",
    "final_data = np.expand_dims(final_data, axis=0)\n",
    "\n",
    "final_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amortized Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = amortizer.sample(final_data, n_samples=N_SAMPLES)\n",
    "sns.pairplot(pd.DataFrame(samples, columns=PARAM_NAMES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_data = data_subset[:, -3:]\n",
    "pred_data = var_dm_pp_check(emp_data, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pred_data[0, :]\n",
    "quantiles = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "np.quantile(tmp[:, 0], quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_amplitude  = np.round(np.sort(np.unique(amplitude)), 3)\n",
    "n_sim             = samples.shape[0]\n",
    "rt_quantiles      = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "pred_rt_quantiles = np.empty((n_sim, 10, len(rt_quantiles)))\n",
    "\n",
    "for sim in range(n_sim):\n",
    "        # iterate over amplitudes\n",
    "        for i in range(len(unique_amplitude)):\n",
    "            tmp_data = pred_data[sim, (pred_data[sim, :, 2] == unique_amplitude[i]), :]\n",
    "            pred_rt_quantiles[sim, i] = np.quantile(tmp_data[:, 0], rt_quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rt_quantiles = np.quantile(pred_rt_quantiles, [0.025, 0.5, 0.975], axis=0)\n",
    "pred_rt_quantiles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_rt_quantiles = np.empty((10, len(rt_quantiles)))\n",
    "for i in range(len(unique_amplitude)):\n",
    "    tmp_data = emp_data[(np.round(emp_data[:, 0], 3) == unique_amplitude[i]), 2]\n",
    "    emp_rt_quantiles[i] = np.quantile(tmp_data, rt_quantiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_rt_quantiles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(rt_quantiles)):\n",
    "    plt.plot(range(len(unique_amplitude)), pred_rt_quantiles[1, :, i], label=\"Predicted Mean\", linestyle='dashed')\n",
    "    plt.fill_between(range(len(unique_amplitude)), pred_rt_quantiles[0, :, i], pred_rt_quantiles[2, :, i],\n",
    "                     alpha=0.2, label=\"Predictive Uncertainty\")\n",
    "    plt.plot(range(len(unique_amplitude)), emp_rt_quantiles[:, i], label=\"Empirical Quantiles\",\n",
    "             linestyle=\"solid\")\n",
    "plt.xticks(range(len(unique_amplitude)), unique_amplitude, rotation=45)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6b7f1a7a462c052d4476dd7bda5c972951aff7e4db39d3058ebed35832beea85"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('cognitiveModeling': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
